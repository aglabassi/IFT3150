
<!DOCTYPE html>
<html>

<head>
  <title>IFT3150 - Abdel Ghani Labassi </title>
</head>
<body>
  <h1>IFT3150 - Projet d'informatique</h1>
  <h2> Détection de dépression et de suicide sur Twitter </h2>
  <h2>Par Abdel Ghani Labassi </h2>
  <h2>Supervisé par <a href="http://rali.iro.umontreal.ca/nie/jian-yun-nie/"> Prof. Jian-Yun Nie </a></h2>
  <ul>
    <li><a href="#Enonce">Énoncé du projet</a></li>
    <li><a href="#Description">Description détaillée</a></li>
    <li><a href="#Plan">Plan de développement</a></li>
    <li><a href="#Rapports">Rapports d'avancement</a></li>
	<li><a href="#RapportFinal">>Résumé du rapport final</a></li>
  </ul>
  <div id="Enonce">
      <h2>Énoncé du projet</h2>
	  <p> 
	  	La dépression et le suicide sont devenus des problèmes de plus en plus préoccupants dans notre société. Une détection à temps de ces problèmes peut aider à sauver des vies. Le travail de ce projet consiste à explorer la possibilité de détecter des signaux de dépression et de suicide sur les réseaux sociaux où beaucoup d'internautes échangent des informations et leurs pensées. Des personnes ayants la dépression ou des idées suicidaires peuvent les exprimer sur les réseaux sociaux. Notre travail est une étude de faisabilité dans l'automatisation de cette détection. Le projet est subventionnée par L'Agence de la santé publique du Canada via une subvention à l'entreprise Sightline avec qui des chercheurs de McGill et de l'UdeM collaborent.
	  </p> 

	<p> 
  		La tâche de détection peut être vue comme une tâche de classification: est-ce qu'un post sur Twitter (un tweet) montre des signaux de dépression ou de suicide? Pour cela, nous allons explorer différents types d'informations: les mots dans le post, le sentiment que ces mots expriment, les caractéristiques de l'utilisateur (e.g. fréquence d'utilisation de Twitter), le cercle d'amis sur Twitter, etc. Ces informations seront extraites à partir des données de Twitter en utilisant l'extraction de l'information et des outils de traitement de langue naturelle. Parmi les techniques de classification envisagées, nous allons tester des techniques de classification classiques comme Naive Bayes, l'arbre de décision, mais aussi les techniques d'apprentissage profond (e.g. représenter des mots par des embeddings). Ces techniques, supervisés, devront être investigués seulement l'annotation des données complétés par des chercheurs de McGill. En attente de cela, je vais explorer les techniques non-supervisées pour mieux comprendre la structure du jeu de données receuilli.
    </p>


  </div>
  <div id="Description">
    <h2>Description détaillée</h2>
	<p>
		J'utiliserai la librairie Sci-kit learn pour investiguer les techniques d'apprentissages classiques, et PyTorch pour les techniques d'apprentissage profond, une fois les données annotés. Pour les contraintes matériels, j'aurai accès à des GPU puissantes lorsqu'il s'agira d'entraîner les modèles, mais pour la phase de developpement logiciel, une ample machine suffit. En attendant l'annotation des données, j'envisage me familiariser avec les techniques non-supervisées, et en particulier, implémenter le modèle proposé dans l'article <a href="https://www.aclweb.org/anthology/W15-1509"> Short Text Clustering via Convolutional Neural Networks </a> à l'aide de PyTorch et le tester sur le jeu de données avant l'annotation.

	


  </div>
  <div id="Plan">

    <h2>Plan de développement</h2>
	
	<p> Date de début: 10 septembre <br/> 
		Date de fin : 1er décembre
		Date de présentation : à confirmer

	</p>

	
	<p>Plan pour le mois de septembre (avant l'annotation des données) : </p>
	
	<ul>
      <li>Se familiariser avec les techniques d'apprentissages non-supervisées </li>
      <li>Prendre connaissance du jeu de données </li>
      <li>Implémenter le modèle décrit dans l'article cité plus haut et le tester sur le jeu de données </li>
	</ul>
	
	<p>À planifier (après l'annotation des données) : </p>
	<ul>
	  <li>Fusionnement des tweets avec informations personelles</li>
	  <li>Étude de l'impact des informations personnelles sur la détection</li>
	  <li>Exploration d'algorithmes d'apprentissage classique </li>
	  <li>Exploration des méthodes d'apprentissage profond </li>
	</ul>


  </div>
  <div id="Rapports">
    <h2>Rapports d'avancement</h2>

	<h3>Semaine 2 : 10 au 14 septembre</h3>

	<p> 

		Mise en place du site web <br/> 

		Lecture approfondie de l'article <a href="https://www.aclweb.org/anthology/W15-1509"> Short Text Clustering via Convolutional Neural Networks </a> <br />

	    Se familiariser avec le partionnement en k-moyennes (k-means clustering) </p> 
	
	


	<h3>Semaine 3 : 17 au 21 septembre</h3>
	
	<p>Mise en place du site web et prendre connaissance du gradient stochastique</p>

	


	<h3>Semaine 4 : 24 au 28 septembre</h3>
	
	<p>Pour se familliariser avec le gradient stochastique et le code déjà en place, j'ai commencé à implémenter la version de base avec un pas fixe.
	 Il y a eu quelque défis dans la compréhension du code, car le concept de batch implémenter ainsi que le modèle (Logit) ne sont pas induitifs.
     J'ai du demander de l'aide au concepteur du code.	 </p>

	


	<h3> Semaine 5 : 3 au 6 octobre</h3>
	
	<p>Continuer l'implémentation du gradient stochastique</p>
	
	


	<h3>Semaine 6 : 8 au 12 octobre</h3>
	
	<p>Terminer l'implémentation du gradient stochastique, mais on cherche le meilleur pas fixe. La façon de déterminer était par cadriage et en observant graphiquement 
    les différences de la fonction objective selon les différents pas. On remarque la fonction objective agie d'une façon particulière. Cela est du  
    par la convexivité des données et de la caractéristique lisse du modèle obtenue de celles-ci. Après discussion, on conclut que cette façon de faire n'est pas idéal
	qu'un critère d'arrêt par cross validation pourrait mieux pour la méthode et ainsi analyser les différentes performance du pas fixe.</p>
	



	<h3>Semaine 7 : 15 au 20 octobre</h3>
	
	<p>Recherche sur la cross-validation, mais je me suis principalement concentré sur ma préparation à l'intra et mes travaux dans mes autres cours</p>
	




	<h3>Semaine de lecture</h3>
	
	<p>Implémentation du critère d'arrêt par la cross-validation. J'ai commencé par observer graphique le comportement de deux modèles fait par différent sous-ensemble des données; soit un 
	ensemble d'entraînement et un ensemble de validation. Après correction du code, on réalise que, par la façon que les données sont générées, il n'y a aucun différence ce qui fait un critères
	d'arrêt par le cross validation serait inefficase puisque nous rencontrions jamais de différence pour avoir un arrêt. Puis, si on revient à la source de ce qu'est le gradient stochastique, ce 
	critère d'arrêt fait perdre sa propriété première soit sa vitesse calculatoire. On ralentit le code en place en le forcant à évaluer deux fonctions objectifs qui ont autant de termes à évaluer
	qu'il y a de données dans les ensembles d'entraînement et de la validation. Ainsi, il faudra faire des recherches sur les critères d'arrêt en apprentissage machine auquel la méthode du gradient
	stochastique est régulièrement utilisée</p>
	








	<h3>Semaine 8: 28 octobre au 2 novembre</h3>
	<p>Recherche dans la littérature et parmis le personnel enseignant pour avoir réponse au critère d'arrêt. Après avoir demander à un étudiant travaillant au Mila et au professeur Ioannis Mitliagkas,
	il propose trois approches pour le critère d'arrêt surtout vu en apprentissage machine: 1) Faire l'évaluation moins fréquemment. 2) Ne prendre qu'un sous ensemble de notre ensemble de validation. 3) Prendre encore 
    un sous ensemble de notre ensemble de validation, mais de travailler en mini batch. </p><p>Par contre, la façon de faire la plus fréquente est de faire un early stop. </p>
	<h3>Semaine 9 : 5 au 9 novembre</h3>
	<p> Après plus ample recherche, un article intéressant fut trouver: <em> Automatic early stopping using cross validation: quantifying the criteria </em> par Lutz Prechelt.
	On y expérimente trois critères d'arrêt pour faire dur early stopping. Ils ont été développé avec l'idée d'un certaine tolérance face à une augmentation de la fonction objective
	moyenne de l'ensemble de validation. La première proposée est de forcer l'arrêt quand la proportion de la fonction objective moyenne de l'ensemble de validation sur son meilleur 
	résultat (soit son minimum) dépasse un certain seuil. La seconde est de calculer la proportion de descente de la fonction objective moyenne de l'ensemble de "training"
	 et d'en plus de considérer la proportion d'augmentation pour en faire une proportion qui provoquera aussi l'arrêt si elle dépasse un seuil. Puis, le dernier critère
	 est d'arrêt le processus lorsqu'il y a k évaluations du critères auquel la fonction objective moyenne de la validation augmentent; ce critère est celui utilisé en python.
	Après discussion, il a été décidé de coder les critères d'arrêts pour voir le comportement de ceux-y</p>
	<h3>Semaine  10: 12 au 16 novembre</h3>
	<p> Une suite de péripities personnelles (notamment du bris de mon ordinateur) a fait que le codage des critère a été retardé. Par contre, quelque recherche et discussion ont permis une meilleur compréhension
     des critères et du domaine</p>
	<h3>Semaine 11: 19 au 23 novembre</h3>
	<p> Les critères ont été fait et un remaniement du code aussi du gradient stochastique. On peut aussi voir que le gradient stochastique bien que rapide est contraint
    par la quantité de paramètre à définir pour son bon comportement que ça soit par la définition du la longueur du pas, le nombre d'itération entre les évalutions d'un
    critères d'arrêt ou la tolérance de celui-ci. Ainsi, on peut donc considérer tester plusieurs longueurs de pas et avec cette étape terminée, passer au code du gradient stochastique moyenne.</p>
	<h3>Semaine 12 : 26 au 30 novembre</h3>
	<p> Un test avec avec 6 longueurs de pas a été fait avec l'aide de mini-batch de longueur 1000 et avec 150 epochs. Il fut intéressant de remarquer le comportement des différents graphiques
    il a été convenu de réessayer avec plus d'epoch. Puis, l'implémentation du gradient moyen stochastique de base a été fait sans trop de mal et il a été possible de voir une certaine rapidité de convergence
    lors des premières itération. Les résultats étaient pour l'instant que sur une petite portion des données et ainsi, une exécution avec l'ensemble sera nécessaire. De plus, pour vraiment bien comparer les 
	résultat avec le gradient stochastique, une implémentation de mini-batch a été convenu de faire et sans oublier d'ajouter les critères d'arrêt implémentés dans les dernières semaines.</p>
	<h3>Semaine 13 : 3 au 7 décembre </h3>
	<h3></h3>
  </div>
  <div id="RapportFinal">>
    <h2>Résumé du rapport final</h2>
	les objectifs principaux du projet étaient l’implémentation de la méthode dugradient moyen stochastique, la vérification de l’article, étudier son utilisation sur des modèles dechoix discrets et de mettre au défi cette méthode sur des hypothèses relâchées et n’ont pas tousété atteints. On explique cela par le temps considérable qu’a pris l’apprentissage des concepts, ducode précédent et un peu du langage de programmation Julia et la programmation de nouvellestâches apparues durant le travail comme d’implémenter le gradient stochastique et un critèred’arrêt. À la base, je connaissais seulement quelques méthodes d’optimisation linéaire et nonlinéaire déterministes et donc, il faut admettre les méthodes stochastiques sont un peu moinsintuitives principalement par leur convergence en espérance et que certains comportements quivaut leur bonne performance ne sont pas encore tout à fait bien expliqués. Pour revenir au côtéprogrammation, on conviendra que de partir avec le code d’une autre personne peut être arduet dans mon cas, il est arrivé quelques fois, lorsque j’allais demander de l’aide, que le concepteur16
du code doive faire quelques réarrangements menant à un léger retardement. De plus, il fautmentionner qu’il y a eu quelques embuches en cours de route, comme le temps énorme queprenait l’exécution des méthodes sur mon ordinateur et ainsi que le bris de celui-ci. Néanmoins,la méthode du gradient stochastique et trois critères d’arrêt ont été achevés et sont fonctionnels.On en viendra à la conclusion que la terminaison des méthodes stochastiques comme le GS etGMS pose vraiment problème et qu’il serait vraiment intéressant de pousser la recherche. Il seraitenvisageable de tenter de développer un critère ne se basant pas sur un ensemble de validationou de voir à utiliser les propriétés statistiques de ces méthodes dérivant un test d’hypothèsestatistique ou un intervalle de confiance. Quoi qu’il en soit, il n’y a que l’implémentation dugradient moyen stochastique de base avec des expérimentations sur des données synthétiquesqui a été fait dans les objectifs ; on dit « de base » puisqu’il reste encore quelques modificationsà faire pour améliorer son efficacité et qu’il soit équivalent à ce qui a été utilisé dans l’article,soit d’ajouter : la recherche linéaire, la capacité à s’adapter à la structure du gradient, unerégularisation efficace et réévaluation du poids des premières itérations. Puis, pour être certaind’avoir complété l’implémentation, il sera nécessaire de tester avec d’autres données puisqueles données synthétiques ne sont pas représentatives d’une situation réelle. Il restera ensuitede procéder aux comparaisons avec les autres méthodes vues dans l’article et la vérificationde celui-ci sera terminée et analysée sur des modèles à choix discret. Si ces tests confirmentles performances du gradient stochastique, il serait intéressant de mettre à contribution cetteméthode pour estimer un modèle et tenter de prédire des choix discrets dans un vrai contexte.Puis, on a testé jusqu’ici avec un modèle Logit, mais on dispose maintenant d’un modèle Mixed-Logit et il serait donc possible de tester avec ce nouveau modèle. Ainsi après toutes ses étapes,il sera possible de s’amuser à relâcher les hypothèses, par exemple de convexité, et l’on auraenfin une bonne connaissance des capacités de la méthode du gradient moyen stochastique. Puis,pour les résultats des expérimentations du rapport, il donne un bon avant-goût de commentse comportera le GMS lorsqu’il se finit d’implémenter. On remarque, comme mentionné dansl’article, que la divergence est facile si le choix de la longueur est inadéquat, mais, pour unemême valeur de fonction d’objectif, il converge définitivement plus rapidement. Conséquemment,il reste beaucoup de travail à faire, mais ses performances sont encourageantes et ce projet mérited’être poursuivi selon les pistes évoquées dans cette conclusion, surtout celles qui permettraientde trouver un meilleur critère d’arrêt stochastique.
  </div>
  
</body>

</html>
