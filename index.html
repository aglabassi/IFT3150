
<!DOCTYPE html>


<html>

<head>
  <title>IFT3150 - Abdel Ghani Labassi </title>
</head>
<body>
  

  <h1>IFT3150 - Projet d'informatique</h1>
  <h2> Détection de dépression et de suicide sur Twitter </h2>
  <h2>Par Abdel Ghani Labassi </h2>
  <h2>Supervisé par <a href="http://rali.iro.umontreal.ca/nie/jian-yun-nie/"> Prof. Jian-Yun Nie </a></h2>

  <h2>Code</h2>
  	<p>
  		Le code lié à la partie "programmation" est disponible à cette <a href="https://github.com/aglabassi/IFT3150"> adresse </a>
  	</p>
  	

  <h2>Sommaire</h2>

  <ul>
    <li><a href="#Enonce">Énoncé du projet</a></li>
    <li><a href="#Description">Description détaillée</a></li>
    <li><a href="#Plan">Plan de développement</a></li>
    <li><a href="#Rapports">Rapports d'avancement</a></li>
	<li><a href="#RapportFinal"> Résumé du rapport final</a></li>
  </ul>


  <div id="Enonce">
      <h2>Énoncé du projet</h2>
	  <p> 
	  	La dépression et le suicide sont devenus des problèmes de plus en plus préoccupants dans notre société. Une détection à temps de ces problèmes peut aider à sauver des vies. Le travail de ce projet consiste à explorer la possibilité de détecter des signaux de dépression et de suicide sur les réseaux sociaux où beaucoup d'internautes échangent des informations et leurs pensées. Des personnes ayants la dépression ou des idées suicidaires peuvent les exprimer sur les réseaux sociaux. Notre travail est une étude de faisabilité dans l'automatisation de cette détection. Le projet est subventionnée par L'Agence de la santé publique du Canada via une subvention à l'entreprise Sightline avec qui des chercheurs de McGill et de l'UdeM collaborent.
	  </p> 

	<p> 
  		La tâche de détection peut être vue comme une tâche de classification: est-ce qu'un post sur Twitter (un tweet) montre des signaux de dépression ou de suicide? Pour cela, nous allons explorer différents types d'informations: les mots dans le post, le sentiment que ces mots expriment, les caractéristiques de l'utilisateur (e.g. fréquence d'utilisation de Twitter), le cercle d'amis sur Twitter, etc. Ces informations seront extraites à partir des données de Twitter en utilisant l'extraction de l'information et des outils de traitement de langue naturelle. Parmi les techniques de classification envisagées, nous allons tester des techniques de classification classiques comme Naive Bayes, l'arbre de décision, mais aussi les techniques d'apprentissage profond (e.g. représenter des mots par des embeddings). Ces techniques, supervisés, devront être investigués seulement l'annotation des données complétés par des chercheurs de McGill. En attente de cela, je vais explorer les techniques non-supervisées pour mieux comprendre la structure du jeu de données receuilli.
    </p>
  </div>


  <div id="Description">
    <h2>Description détaillée</h2>
	<p>
		J'utiliserai la librairie Scikit-learn pour investiguer les techniques d'apprentissages classiques, et PyTorch pour les techniques d'apprentissage profond, une fois les données annotés. Pour les contraintes matériels, j'aurai accès à des GPU puissantes lorsqu'il s'agira d'entraîner les modèles, mais pour la phase de developpement logiciel, une machine ample suffit. En attendant l'annotation des données, j'envisage me familiariser avec les techniques non-supervisées, et en particulier, implémenter le modèle proposé dans l'article <a href="https://www.aclweb.org/anthology/W15-1509"> Short Text Clustering via Convolutional Neural Networks (Xu) </a> à l'aide de PyTorch et le tester sur le jeu de données avant l'annotation.

  </div>



  <div id="Plan">

    <h2>Plan de développement</h2>
	
	<p> Date de début: 10 septembre <br/> 
		Date de fin : 1er décembre <br />
		Date de présentation : à confirmer

	</p>

	
	<p>Plan pour le mois de septembre (avant l'annotation des données) : </p>
	
	<ul>
      <li>Se familiariser avec les techniques d'apprentissages non-supervisées </li>
      <li>Prendre connaissance du jeu de données </li>
      <li>Implémenter le modèle décrit dans l'article cité plus haut et le tester sur le jeu de données </li>
	</ul>
	
	<p>À planifier (après l'annotation des données) : </p>
	<ul>
	  <li>Entrainer + tester le modèle sur les jeux de données </li>
	  <li>Comparer avec l'approche supervisé en utilisant un RNN </li>

	</ul>
  </div>


  <div id="Rapports">
    <h2>Rapports d'avancement</h2>

	<h3>Semaine 2 : 9 au 16 septembre</h3>

	<p> 
		Objectif :

		<ul>
      		<li> Mise en place du site web </li>
      		<li> Lecture approfondie de l'article <a href="https://www.aclweb.org/anthology/W15-1509"> Short Text Clustering via Convolutional Neural Networks </a> </li>
      		<li> Se familiariser avec le partionnement en k-moyennes (k-means clustering) </li>
		</ul>

	    Bilan : <br/> 
	    les objectifs ont tous étés réalisés. Un résumé du modèle sera décrite dans le rapport finale, de même que sur la méthode des k-means.

	</p> 


	<h3>Semaine 2 : 16 au 23 septembre</h3>

	<p> 
		Objectif :
		<ul>
      		<li> Commencer l'implémentation </li>
      		<li> Acquérire les embeddings </li>
      		<li> Coder des fonctions auxilliaire de traitement de l'inputs </li>
      		<li> Coder le réseau de neuronnes convolutif  </li>
      		<li> Coder l'embeddeur binaire  </li>
		</ul>

		Bilan: <br/> 
		J'ai décidé de commencé par l'implémentation de l'embeddeur binaire, car il est nécessaire au fonctionnement du réseaux de neuronnes. J'ai été contraint à me documenter sur la méthode du "laplacian eighenmap" (que je résumerai dans le rappport final) pour résoudre le problème d'optimisation permettant d'avoir le code binaire. Je me suis documenté sur son implementation sur sklearn, portant le nom de "spectral embedding". La bibliothèque propose des choix de matrices de similarités différentes que celle proposé dans l'article. J'ai donc été contraint d'implémenter le calculateur de matrices de similarités manuellement. Ensuite, j'ai testé l'embeddeur binaire sur le dataset "The Digit Dataset", et les résultats furent prometteur : en utilisant le code binaire avec dimension q=10, soit 6 fois moins de features que les features original (8x8=64), l'accuracy fut de 86% (réduit) vs 88% (original) avec Naive Bayes. Je n'ai pas eu le temps de commencer l'implémentation du réseau de neuronnes convolutif.

	</p> 

	<h3>Semaine 3 : 23 au 30 septembre</h3>

	<p> 
		Objectif :
		<ul>
      		<li> Finir l'implémentation du réseau de neuronne convolutif </li>
      		<li> Finir le "main.py" (i.e mettre toute les parties ensemble) </li>
      		<li> Reccuillir les données brutes non-annotées  </li>
      		<li> Tester, hyperparameter tuning </li>
		</ul>

		Bilan: <br/>  
		J'ai fini l'implémentation du CNN. J'ai toutefois sous-estimé le temps que cela me prendrait : l'article décrivait de manière très "haut niveau" le fonctionnement du CNN. J'ai donc du me documenter plus en profondeur sur l'architecture du modèle proposé, et j'ai donc lu l'article <a href="https://www.aclweb.org/anthology/P14-1062/"> A Convolutional Neural Network for Modelling Sentences (Kalchbrenner) </a>  qui décrivait la même architecture que celle proposé dans <i>Xu </i>. Cela m'a permis d'appronfondir mes connaissances sur les architectures des réseaux de neuronnes utilisé pour modeliser des phrases (et non pas pour les classifier). En particulier, j'ai implémenté le "Dynamic k-Max Pooling" tel que expliqué dans <i> Kalchbrenner </i>  à l'aide de Pytorch.
	
	</p> 

	<h3>Semaine 4 : 1 au 7 octobre </h3>

	<p> 
		Objectif :
		<ul>
      		<li> Tester tous le système sur le dataset <a href="https://competitions.codalab.org/competitions/20011"> OffensEval 2019</a> et debugger   </li>
      		<li> Receuillir le dataset cible (depression et suicide sur Twitter) </li>
		</ul>

		Bilan: J'ai réalisé qu'il fallait beaucoup de travail pour entrainer le réseau de neuronne. J'ai commencé à me documenter sur cela, en particulier comment entrainer les réseaux de neuronnes pour la modélisation de phrase.
		
	</p> 

	<h3>Semaine 5 : 7 au 14 octobre </h3>

	<p> 
		Objectif :
		Note: je planifie mettre moins de temps cette semaine pour le projet, en raison de la mi-session.
		<ul>
			<li> Se documenter sur l'entrainement de réseaux neuronnaux pour la modélisation de phrase </li>
      		<li> Coder la fonction train_model et la tester </li>
		</ul>

		Bilan:  J'ai codé la fonction train_model, toutefois, l'apprentissage ne se fait pas comme prévue : 
		le loss ne diminue pas. Je vais régler ce problème après la semaine de relache. J'ai également récolté le dataset Sentiment140, qui est plus pertinent que le OffenEval 2019 dans le contexte qui m'a été donné.
		
	</p> 

	<h3>Semaine 5 : 14 au 21 octobre </h3>

	<p> 
		Objectif :
		Note: je planifie mettre moins de temps cette semaine pour le projet, en raison de la mi-session.
		<ul>
			<li> Se documenter sur l'entrainement de réseaux neuronnaux via GPU</li>
      		<li> Apprendre à utiliser CUDA et Google Colab (pour lancer les calculs d'entrainment sur des GPUs puissantes de Google) </li>
		</ul>

		Bilan: 
		
	</p> 



  </div>





  <div id="RapportFinal">
  	<h2>Résumé du rapport final</h2>
  
  </div>
  
</body>

</html>
